
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Scikit-Learn compatible embeddings">
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.1.21">
    
    
      
        <title>Utils - Embetter Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.eebd395e.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetbrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Jetbrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#utils" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Embetter Docs" class="md-header__button md-logo" aria-label="Embetter Docs" data-md-component="logo">
      
  <img src="../../images/icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Embetter Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Utils
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/koaning/embetter" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../finetuners/" class="md-tabs__link">
      Finetuners
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../applications/" class="md-tabs__link">
      Techniques
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../text/" class="md-tabs__link">
        API
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Embetter Docs" class="md-nav__button md-logo" aria-label="Embetter Docs" data-md-component="logo">
      
  <img src="../../images/icon.png" alt="logo">

    </a>
    Embetter Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/koaning/embetter" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../finetuners/" class="md-nav__link">
        Finetuners
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../applications/" class="md-nav__link">
        Techniques
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../text/" class="md-nav__link">
        Text
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../vision/" class="md-nav__link">
        Vision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../multimodal/" class="md-nav__link">
        MultiModal
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../external/" class="md-nav__link">
        External
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../finetune/" class="md-nav__link">
        Finetuners
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../model/" class="md-nav__link">
        Model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="utils">Utils</h1>
<h2 id="cached">cached</h2>



<div class="doc doc-object doc-function">





  <div class="doc doc-contents first">
  
      <p>Uses a <a href="https://grantjenks.com/docs/diskcache/tutorial.html">diskcache</a> in
an attempt to fetch precalculated embeddings from disk instead of inferring them.
This can save on compute, but also cloud credits, depending on the backend
that you're using to generate embeddings.</p>
<p>Be mindful of what does in to the encoder that you choose. It's preferable to give it
text as opposed to numpy arrays. Also note that the first time that you'll run this
it will take more time due to the overhead of writing into the cache.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>name</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the name of the local folder to represent the disk cache</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>pipeline</code></td>
          <td>
                <code><span title="sklearn.base.BaseEstimator">BaseEstimator</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the pipeline that you want to cache</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>
      <p>Usage:
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">embetter.text</span> <span class="kn">import</span> <span class="n">SentenceEncoder</span>
<span class="kn">from</span> <span class="nn">embetter.utils</span> <span class="kn">import</span> <span class="n">cached</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">cached</span><span class="p">(</span><span class="s2">&quot;sentence-enc&quot;</span><span class="p">,</span> <span class="n">SentenceEncoder</span><span class="p">(</span><span class="s1">&#39;all-MiniLM-L6-v2&#39;</span><span class="p">))</span>

<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;this is a pretty long text, which is more expensive </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)]</span>

<span class="c1"># This might be a bit slow ~17.2s on our machine</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

<span class="c1"># This should be quicker ~4.71s on our machine</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>
</code></pre></div></p>
<p>Note that you're also able to fetch the precalculated embeddings directly via:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">diskcache</span> <span class="kn">import</span> <span class="n">Cache</span>

<span class="c1"># Make sure that you use the same name as in `cached`</span>
<span class="n">cache</span> <span class="o">=</span> <span class="n">Cache</span><span class="p">(</span><span class="s2">&quot;sentence-enc&quot;</span><span class="p">)</span>
<span class="c1"># Use a string as a key, if it&#39;s precalculated you&#39;ll get an array back.</span>
<span class="n">cache</span><span class="p">[</span><span class="s2">&quot;this is a pretty long text, which is more expensive 0&quot;</span><span class="p">]</span>
</code></pre></div>

          <details class="quote">
            <summary>Source code in <code>embetter/utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">cached</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">:</span> <span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Uses a [diskcache](https://grantjenks.com/docs/diskcache/tutorial.html) in</span>
<span class="sd">    an attempt to fetch precalculated embeddings from disk instead of inferring them.</span>
<span class="sd">    This can save on compute, but also cloud credits, depending on the backend</span>
<span class="sd">    that you&#39;re using to generate embeddings.</span>

<span class="sd">    Be mindful of what does in to the encoder that you choose. It&#39;s preferable to give it</span>
<span class="sd">    text as opposed to numpy arrays. Also note that the first time that you&#39;ll run this</span>
<span class="sd">    it will take more time due to the overhead of writing into the cache.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        name: the name of the local folder to represent the disk cache</span>
<span class="sd">        pipeline: the pipeline that you want to cache</span>

<span class="sd">    Usage:</span>
<span class="sd">    ```python</span>
<span class="sd">    from embetter.text import SentenceEncoder</span>
<span class="sd">    from embetter.utils import cached</span>

<span class="sd">    encoder = cached(&quot;sentence-enc&quot;, SentenceEncoder(&#39;all-MiniLM-L6-v2&#39;))</span>

<span class="sd">    examples = [f&quot;this is a pretty long text, which is more expensive {i}&quot; for i in range(10_000)]</span>

<span class="sd">    # This might be a bit slow ~17.2s on our machine</span>
<span class="sd">    encoder.transform(examples)</span>

<span class="sd">    # This should be quicker ~4.71s on our machine</span>
<span class="sd">    encoder.transform(examples)</span>
<span class="sd">    ```</span>

<span class="sd">    Note that you&#39;re also able to fetch the precalculated embeddings directly via:</span>

<span class="sd">    ```python</span>
<span class="sd">    from diskcache import Cache</span>

<span class="sd">    # Make sure that you use the same name as in `cached`</span>
<span class="sd">    cache = Cache(&quot;sentence-enc&quot;)</span>
<span class="sd">    # Use a string as a key, if it&#39;s precalculated you&#39;ll get an array back.</span>
<span class="sd">    cache[&quot;this is a pretty long text, which is more expensive 0&quot;]</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cache</span> <span class="o">=</span> <span class="n">Cache</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run_cached</span><span class="p">(</span><span class="n">method</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">cache</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cache</span> <span class="k">else</span> <span class="s2">&quot;TODO&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">)}</span>
            <span class="n">text_todo</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;TODO&quot;</span><span class="p">]</span>
            <span class="n">i_todo</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;TODO&quot;</span><span class="p">]</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">method</span><span class="p">(</span><span class="n">text_todo</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">Cache</span><span class="p">(</span><span class="n">cache</span><span class="o">.</span><span class="n">directory</span><span class="p">)</span> <span class="k">as</span> <span class="n">reference</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">x_tfm</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">i_todo</span><span class="p">,</span> <span class="n">text_todo</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
                    <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_tfm</span>
                    <span class="n">reference</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">x_tfm</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">arr</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>

        <span class="k">return</span> <span class="n">wrapped</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">run_cached</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pipeline</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div><h2 id="batched">batched</h2>



<div class="doc doc-object doc-function">





  <div class="doc doc-contents first">
  
      <p>Takes an iterable and turns it into a batched iterable.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>iterable</code></td>
          <td>
                <code><span title="typing.Iterable">Iterable</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the input stream</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>n</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the batch size</p>
            </div>
          </td>
          <td>
                <code>64</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>embetter/utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">batched</span><span class="p">(</span><span class="n">iterable</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Takes an iterable and turns it into a batched iterable.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        iterable: the input stream</span>
<span class="sd">        n: the batch size</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n must be at least one&quot;</span><span class="p">)</span>
    <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">islice</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">n</span><span class="p">)):</span>
        <span class="k">yield</span> <span class="n">batch</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div><h2 id="calc_distances">calc_distances</h2>



<div class="doc doc-object doc-function">





  <div class="doc doc-contents first">
  
      <p>Shortcut to compare a sequence of inputs to a set of anchors.</p>
<p>The available metrics are: <code>cityblock</code>,<code>cosine</code>,<code>euclidean</code>,<code>haversine</code>,<code>l1</code>,<code>l2</code>,<code>manhattan</code> and <code>nan_euclidean</code>.</p>
<p>You can read a verbose description of the metrics <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics">here</a>.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>inputs</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>sequence of inputs to calculate scores for</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>anchors</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>set/list of anchors to compare against</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>pipeline</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the pipeline to use to calculate the embeddings</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>anchor_pipeline</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the pipeline to apply to the anchors, meant to be used if the anchors should use a different pipeline</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>metric</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>the distance metric to use</p>
            </div>
          </td>
          <td>
                <code>&#39;cosine&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>aggregate</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>you'll want to aggregate the distances to the different anchors down to a single metric, numpy functions that offer axis=1, like <code>np.max</code> and <code>np.mean</code>, can be used</p>
            </div>
          </td>
          <td>
                <code><span title="numpy.max">max</span></code>
          </td>
        </tr>
        <tr>
          <td><code>n_jobs</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>set to -1 to use all cores for calculation</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>embetter/utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">calc_distances</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">anchors</span><span class="p">,</span>
    <span class="n">pipeline</span><span class="p">,</span>
    <span class="n">anchor_pipeline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
    <span class="n">aggregate</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shortcut to compare a sequence of inputs to a set of anchors.</span>

<span class="sd">    The available metrics are: `cityblock`,`cosine`,`euclidean`,`haversine`,`l1`,`l2`,`manhattan` and `nan_euclidean`.</span>

<span class="sd">    You can read a verbose description of the metrics [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics).</span>

<span class="sd">    Arguments:</span>
<span class="sd">        inputs: sequence of inputs to calculate scores for</span>
<span class="sd">        anchors: set/list of anchors to compare against</span>
<span class="sd">        pipeline: the pipeline to use to calculate the embeddings</span>
<span class="sd">        anchor_pipeline: the pipeline to apply to the anchors, meant to be used if the anchors should use a different pipeline</span>
<span class="sd">        metric: the distance metric to use</span>
<span class="sd">        aggregate: you&#39;ll want to aggregate the distances to the different anchors down to a single metric, numpy functions that offer axis=1, like `np.max` and `np.mean`, can be used</span>
<span class="sd">        n_jobs: set to -1 to use all cores for calculation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X_input</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">anchor_pipeline</span><span class="p">:</span>
        <span class="n">X_anchors</span> <span class="o">=</span> <span class="n">anchor_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">anchors</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_anchors</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">anchors</span><span class="p">)</span>

    <span class="n">X_dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">X_input</span><span class="p">,</span> <span class="n">X_anchors</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">aggregate</span><span class="p">(</span><span class="n">X_dist</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["toc.integrate", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.indexes", "toc.follow", "content.code.copy", "content.code.select", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>